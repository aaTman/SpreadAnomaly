#!/usr/bin/env python2
# -*- coding: utf-8 -*-

import matplotlib as mpl
import numpy as np
from datetime import datetime, timedelta
import seaborn as sns
from matplotlib.colors import Normalize
import sys
from bisect import bisect
from scipy.stats import percentileofscore
sys.path.append('/home/taylorm/mcli/pythonfuncs')
import mclifuncs as mc
import plotter as pt
import gc
import matplotlib.pyplot as plt
import sys
from bs4 import BeautifulSoup
import requests

mpl.use('agg')
"""
Created on Wed Jun  7 16:29:35 2017

@author: taylorm
"""


class MidpointNormalize(Normalize):
    def __init__(self, vmin=None, vmax=None, midpoint=None, clip=False):
        self.midpoint = midpoint
        Normalize.__init__(self, vmin, vmax, clip)

    def __call__(self, value, clip=None):
        # I'm ignoring masked values and all kinds of edge cases to make a
        # simple example...
        x, y = [self.vmin, self.midpoint, self.vmax], [0, 0.5, 1]
        return np.ma.masked_array(np.interp(value, x, y))


def liveLoad(wlon=180, elon=310, slat=20, nlat=80):

    print 'loading GEFS file'
    dateArr, date1, mslpMean, mslpStd, mslppmm, lats, lons, tmpMean, tmpStd, hgtMean, hgtStd, tmppmm, hgtpmm = mc.GEFSload()
    print 'loaded GEFS file'
    liveDate = datetime.strptime(date1, "%Y%m%d%H")

    dates = mc.mcliTimeArray(var='mslp')
    ind = mc.mcliSub(dates, liveDate)
    mcliArr = mc.mcliLoad(var='mslp', ind=ind)
    #tempmcliArr= mc.mcliLoad(var='850tmp',ind=ind)

    print 'returning GEFS values to main m-climate function'
    return ind, liveDate, dateArr, mslpMean, mslpStd, mslppmm,mcliArr,  lats, lons, tmpMean, tmpStd, hgtMean, hgtStd, tmppmm, hgtpmm


def subsetMCli(slpm, slps, m630, s630):

    mstdgrid = np.ones_like(slpm)
    mmngrid = np.ones_like(slpm)
    pgrid = np.ones_like(slpm)
    bsgrid = np.ones_like(slpm)
#    if m630 == 0 or s630 == 0:
#        return pgrid,pgrid,pgrid

    for y in range(0, np.shape(slpm)[-2]):
        for z in range(0, np.shape(slpm)[-1]):
            marg = m630[:, y, z].argsort()
            mbins = m630[marg, y, z]
            sbins = s630[marg, y, z]
            leng = len(mbins)

            centRange = bisect(mbins.tolist(), slpm[y, z])

            if centRange <= leng/10:
                subsetSpread = sbins[0:leng/10]
                pgrid[y, z] = percentileofscore(subsetSpread, slps[y, z])
                mstdgrid[y, z] = np.std(subsetSpread)
                mmngrid[y, z] = np.mean(subsetSpread)
            elif centRange >= leng-leng/10:
                subsetSpread = sbins[leng-leng/10:]
                pgrid[y, z] = percentileofscore(subsetSpread, slps[y, z])
                mstdgrid[y, z] = np.std(subsetSpread)
                mmngrid[y, z] = np.mean(subsetSpread)
            else:
                subsetSpread = sbins[centRange-leng/20:centRange+leng/20]
                pgrid[y, z] = percentileofscore(subsetSpread, slps[y, z])
                mstdgrid[y, z] = np.std(subsetSpread)
                mmngrid[y, z] = np.mean(subsetSpread)

            bsgrid[y, z] = percentileofscore(sbins, slps[y, z])

    ssaAnom = (slps - mmngrid)/mstdgrid
    gc.collect()
    return pgrid, bsgrid, ssaAnom


def mainfunc():

    mc.GEFScheck()
    ind, date, dateArr, mslpMean, mslpStd, mslppmm, mcliArr, lats, lons, tmpMean, tmpStd, hgtMean, hgtStd, tmppmm,hgtpmm = liveLoad()
    gc.collect()
    # slprfArr=mcliArr[0]
    if datetime.now().month == 11:
        datefhour = dateArr
        dateArr = [date+timedelta(hours=n) for n in dateArr]
        ssaAnomT = 0
        subsetPercT = 0
        totalPercT = 0
        slpArrMean = mcliArr[0]
        slpArrStd = mcliArr[1]
        mcliArr = None
        gc.collect()
        subsetPerc = np.ones_like(mslpMean)
        totalPerc = np.ones_like(mslpMean)
        ssaAnom = np.ones_like(mslpMean)
        for i in range(0, len(mslpMean)):
            subsetPerc[i], totalPerc[i], ssaAnom[i] = subsetMCli(mslpMean[i], mslpStd[i], slpArrMean[:, i], slpArrStd[:, i])

        gc.collect()

        [pt.slpplotMaker(date, mslpMean[i], mslpStd[i], datefhour[i], dateArr[i], ssaAnom[i], subsetPerc[i], totalPerc[i], mslppmm[i], lats, lons) for i in range(0, len(mslpMean))]

        gc.collect()
        [pt.tmpplotMaker(date, tmpMean[i], tmpStd[i], datefhour[i], dateArr[i], ssaAnomT, subsetPercT, totalPercT, tmppmm[i], lats, lons) for i in range(0, len(mslpMean))]
        logfi = open('/home/taylorm/ssa/run.txt', 'w')
        # write the details into the log to have a record of what runs were ran through the code
        logfi.write(date.strftime('%Y%m%d%H'))
        # closes file
        logfi.close()
        # path = '/home/taylorm/ssa'
    else:
        temprfArr = mcliArr[1]

        temprfMean = temprfArr[0, :, :, 1, :, :]
        temprfSprd = temprfArr[0, :, :, 0, :, :]

        slpArrMean = np.mean(mcliArr[0], axis=1)
        slpArrStd = np.std(mcliArr[0], axis=1)

        subsetPerc, totalPerc, ssaAnom = subsetMCli(mslpMean, mslpStd, slpArrMean, slpArrStd)
        subsetPercT, totalPercT, ssaAnomT = subsetMCli(tmpMean, tmpStd, temprfMean, temprfSprd)
        datefhour = [date+timedelta(hours=n) for n in dateArr]
        [pt.slpplotMaker(date, mslpMean[i], mslpStd[i], datefhour[i], dateArr[i], ssaAnom[i], subsetPerc[i], totalPerc[i], mslppmm[i], lats, lons) for i in range(0, len(mslpMean))]
        [pt.tmpplotMaker(date, tmpMean[i], tmpStd[i], datefhour[i], dateArr[i], ssaAnomT[i], subsetPercT[i], totalPercT[i], tmppmm[i], lats, lons) for i in range(0, len(mslpMean))]
    logfi = open('/home/taylorm/ssa/run.txt', 'w')
    # write the details into the log to have a record of what runs were ran through the code
    logfi.write(date.strftime('%Y%m%d%H'))
    # closes file

    logfi.close()
    url1 = 'http://thredds.ucar.edu/thredds/catalog/grib/NCEP/GEFS/Global_1p0deg_Ensemble/members/latest.html'

    # Play games with the url to get the TDSCatalog for siphon
    response = requests.get(url1)
    page = str(BeautifulSoup(response.content, 'lxml'))
    start_link = page.find("a href")

    start_quote = page.find('"', start_link)
    end_quote = page.find('"', start_quote + 1)
    url = page[start_quote + 1: end_quote]

    url = url.split('html')
    endurl = url[1]

    # load in year and month as string
    year = endurl[83:87]
    month = endurl[87:89]

    # Load in run and day as string
    run = endurl[92:94]
    day = endurl[89:91]

    # Path to log
    pathCheck = '/home/taylorm/mcli/logs/'

    logC = open(pathCheck+'log', 'a')
    logC.write(run+' '+day+' '+month+' '+year+'\n')
    logC.close()

    # path = '/home/taylorm/ssa'


if __name__ == "__main__":

    sns.set(font_scale=1.65, style="whitegrid", color_codes=True)
    mainfunc()
    sys.exit()
